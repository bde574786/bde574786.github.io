---
title: "Avatar created with AI, warning for criminal abuse"
description: "누군가가 내가 되었다."
author: bde574786
date: 2024-11-04 14:23:00 +0900
categories: [최근 보안 이슈]
tags: [Recent Issue, AI]
image: assets/posts/security-issue/2024-11-04/img-001.png
---

최근 들어 **챗봇 '챗GPT'** 등 **생성형 인공지능(AI) 기술**이 우리의 일상을 편리하게 만들어주고 있지만, 이에 따른 새로운 보안 위협과 악용 가능성도 주목받고 있다. **월스트리트저널(WSJ)**의 IT 칼럼니스트 조안나 스턴은 AI 아바타와 음성 복제 기술이 초래할 수 있는 위험성을 실험을 통해 경고했다.

<br>
### **AI avatar that clones me**

스턴은 런던의 **AI 스타트업 신세시아(Synthesia)**의 프로그램을 활용해 자신의 외모와 움직임을 복제한 **'AI 아바타'**를 만들었다. 생성된 아바타는 실제 자신의 모습을 거울로 보는 것처럼 정교했으며, 여기에 챗GPT로 작성된 대사를 입력해 화상회의와 동영상 공유 사이트에 출연시켰다. 화상회의에서는 **AI 아바타**의 어색한 자세와 감정 부족이 금세 들통났으나, 동영상 공유 사이트처럼 상호작용이 적은 플랫폼에서는 실제와 구별하기 어려운 점을 확인했다.

<br>
## **Voice cloning and biometric bypass experiments**

스턴은 이어 **음성 AI 스타트업 일레븐랩스(ElevenLabs)**를 이용해 자신과 유사한 **'음성 아바타'**를 만들고 가족들에게 테스트를 했다. 여동생은 호흡 조절이 부족하다는 점 외에는 매우 흡사하다고 평가했으며, 아버지 역시 스턴의 목소리와 비슷하다고 착각할 정도였다. 이를 통해, 가족조차 구분하기 어려운 AI 목소리가 다른 이들에게는 더 큰 혼란을 줄 수 있음을 시사했다.

AI로 생성한 음성 아바타는 실제로 은행의 **자동응답시스템(ARS)**에서도 스턴 본인의 목소리로 인식되었다. ARS는 음성 생체인식을 통해 고객을 연결하는데, 이 AI 음성이 해당 시스템을 손쉽게 통과하며 보안 취약성을 드러냈다.

<br>
### **Side effects**

스턴은 이러한 기술이 사회보장번호와 같은 민감한 정보를 묻는 과정에서도 녹음된 것처럼 느껴질 뿐, AI 목소리라는 의심을 받지 않는 경우가 많다는 점을 우려했다. **신세시아**와 **일레븐랩스**의 프로그램 모두 비윤리적 행위에 대한 제한 장치가 없어, 위험한 의도나 악의적인 목적으로도 쉽게 악용될 가능성이 크다는 지적이다.

스턴은 AI 아바타와 음성 복제 기술의 발전이 사회에 긍정적인 변화를 가져올 수 있지만, 그만큼 악용될 가능성도 커지고 있음을 강조했다.

## **Reference**

[https://stock.mk.co.kr/news/view/109303](https://stock.mk.co.kr/news/view/109303)